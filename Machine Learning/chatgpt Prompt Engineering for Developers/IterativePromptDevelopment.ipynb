{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "209cd474-8437-42f2-91ea-824270f59b45",
   "metadata": {},
   "source": [
    "# Iterative Prompt Development Using Gpt-4.5-turbo Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8f868b3-eaa3-4127-8b70-3f50be39f2b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# importing openai package and configuring api key\n",
    "\n",
    "import openai\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "key = load_dotenv(find_dotenv())\n",
    "print(key)\n",
    "openai.api_key = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b0ab4e7-1593-4a82-ba2a-7a473481190d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fucntion for returning response from gpt model\n",
    "\n",
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0, # this is the degree of randomness of the model's output\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877c3dd0-2ee6-4703-baeb-7660cd958abd",
   "metadata": {},
   "source": [
    "## Generate a marketing product description from a product fact sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "675581f8-554f-4931-ab9c-6c15ff081ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_sheet_chair = \"\"\"\n",
    "OVERVIEW\n",
    "- Part of a beautiful family of mid-century inspired office furniture, \n",
    "including filing cabinets, desks, bookcases, meeting tables, and more.\n",
    "- Several options of shell color and base finishes.\n",
    "- Available with plastic back and front upholstery (SWC-100) \n",
    "or full upholstery (SWC-110) in 10 fabric and 6 leather options.\n",
    "- Base finish options are: stainless steel, matte black, \n",
    "gloss white, or chrome.\n",
    "- Chair is available with or without armrests.\n",
    "- Suitable for home or business settings.\n",
    "- Qualified for contract use.\n",
    "\n",
    "CONSTRUCTION\n",
    "- 5-wheel plastic coated aluminum base.\n",
    "- Pneumatic chair adjust for easy raise/lower action.\n",
    "\n",
    "DIMENSIONS\n",
    "- WIDTH 53 CM | 20.87”\n",
    "- DEPTH 51 CM | 20.08”\n",
    "- HEIGHT 80 CM | 31.50”\n",
    "- SEAT HEIGHT 44 CM | 17.32”\n",
    "- SEAT DEPTH 41 CM | 16.14”\n",
    "\n",
    "OPTIONS\n",
    "- Soft or hard-floor caster options.\n",
    "- Two choices of seat foam densities: \n",
    " medium (1.8 lb/ft3) or high (2.8 lb/ft3)\n",
    "- Armless or 8 position PU armrests \n",
    "\n",
    "MATERIALS\n",
    "SHELL BASE GLIDER\n",
    "- Cast Aluminum with modified nylon PA6/PA66 coating.\n",
    "- Shell thickness: 10 mm.\n",
    "SEAT\n",
    "- HD36 foam\n",
    "\n",
    "COUNTRY OF ORIGIN\n",
    "- Italy\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24a8b362-179f-4413-a424-ecbd484201ec",
   "metadata": {},
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 14\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# simple prompt\u001b[39;00m\n\u001b[0;32m      3\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124mYour task is to help a marketing team create a \u001b[39m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;124mdescription for a retail website of a product based \u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;124mTechnical specifications: ```\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfact_sheet_chair\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m```\u001b[39m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m---> 14\u001b[0m response \u001b[38;5;241m=\u001b[39m get_completion(prompt)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(response)\n",
      "Cell \u001b[1;32mIn[3], line 5\u001b[0m, in \u001b[0;36mget_completion\u001b[1;34m(prompt, model)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_completion\u001b[39m(prompt, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-3.5-turbo\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m      4\u001b[0m     messages \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt}]\n\u001b[1;32m----> 5\u001b[0m     response \u001b[38;5;241m=\u001b[39m openai\u001b[38;5;241m.\u001b[39mChatCompletion\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[0;32m      6\u001b[0m         model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m      7\u001b[0m         messages\u001b[38;5;241m=\u001b[39mmessages,\n\u001b[0;32m      8\u001b[0m         temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, \u001b[38;5;66;03m# this is the degree of randomness of the model's output\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     )\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\api_resources\\chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 25\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TryAgain \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     27\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m>\u001b[39m start \u001b[38;5;241m+\u001b[39m timeout:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[1;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[0;32m    137\u001b[0m ):\n\u001b[0;32m    138\u001b[0m     (\n\u001b[0;32m    139\u001b[0m         deployment_id,\n\u001b[0;32m    140\u001b[0m         engine,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[0;32m    151\u001b[0m     )\n\u001b[1;32m--> 153\u001b[0m     response, _, api_key \u001b[38;5;241m=\u001b[39m requestor\u001b[38;5;241m.\u001b[39mrequest(\n\u001b[0;32m    154\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    155\u001b[0m         url,\n\u001b[0;32m    156\u001b[0m         params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[0;32m    157\u001b[0m         headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m    158\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m    159\u001b[0m         request_id\u001b[38;5;241m=\u001b[39mrequest_id,\n\u001b[0;32m    160\u001b[0m         request_timeout\u001b[38;5;241m=\u001b[39mrequest_timeout,\n\u001b[0;32m    161\u001b[0m     )\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[0;32m    164\u001b[0m         \u001b[38;5;66;03m# must be an iterator\u001b[39;00m\n\u001b[0;32m    165\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\api_requestor.py:298\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[1;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    279\u001b[0m     method,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    286\u001b[0m     request_timeout: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    287\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m    288\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_raw(\n\u001b[0;32m    289\u001b[0m         method\u001b[38;5;241m.\u001b[39mlower(),\n\u001b[0;32m    290\u001b[0m         url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    296\u001b[0m         request_timeout\u001b[38;5;241m=\u001b[39mrequest_timeout,\n\u001b[0;32m    297\u001b[0m     )\n\u001b[1;32m--> 298\u001b[0m     resp, got_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpret_response(result, stream)\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resp, got_stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\api_requestor.py:700\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[1;34m(self, result, stream)\u001b[0m\n\u001b[0;32m    692\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m    693\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpret_response_line(\n\u001b[0;32m    694\u001b[0m             line, result\u001b[38;5;241m.\u001b[39mstatus_code, result\u001b[38;5;241m.\u001b[39mheaders, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    695\u001b[0m         )\n\u001b[0;32m    696\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m parse_stream(result\u001b[38;5;241m.\u001b[39miter_lines())\n\u001b[0;32m    697\u001b[0m     ), \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m--> 700\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpret_response_line(\n\u001b[0;32m    701\u001b[0m             result\u001b[38;5;241m.\u001b[39mcontent\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    702\u001b[0m             result\u001b[38;5;241m.\u001b[39mstatus_code,\n\u001b[0;32m    703\u001b[0m             result\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m    704\u001b[0m             stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    705\u001b[0m         ),\n\u001b[0;32m    706\u001b[0m         \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    707\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\api_requestor.py:765\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[1;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[0;32m    763\u001b[0m stream_error \u001b[38;5;241m=\u001b[39m stream \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mdata\n\u001b[0;32m    764\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream_error \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m rcode \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[1;32m--> 765\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_error_response(\n\u001b[0;32m    766\u001b[0m         rbody, rcode, resp\u001b[38;5;241m.\u001b[39mdata, rheaders, stream_error\u001b[38;5;241m=\u001b[39mstream_error\n\u001b[0;32m    767\u001b[0m     )\n\u001b[0;32m    768\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[1;31mRateLimitError\u001b[0m: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors."
     ]
    }
   ],
   "source": [
    "# simple prompt\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Your task is to help a marketing team create a \n",
    "description for a retail website of a product based \n",
    "on a technical fact sheet.\n",
    "\n",
    "Write a product description based on the information \n",
    "provided in the technical specifications delimited by \n",
    "triple backticks.\n",
    "\n",
    "Technical specifications: ```{fact_sheet_chair}```\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8297c9e3-2f5d-41df-83ed-7c8ea3f3183e",
   "metadata": {},
   "source": [
    "### Issue 1: The text is too long\n",
    "#### Limit the number of words/sentences/characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1acc19-844a-4cca-b69e-6792dfa7c948",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Your task is to help a marketing team create a \n",
    "description for a retail website of a product based \n",
    "on a technical fact sheet.\n",
    "\n",
    "Write a product description based on the information \n",
    "provided in the technical specifications delimited by \n",
    "triple backticks.\n",
    "\n",
    "The description is intended for furniture retailers, \n",
    "so should be technical in nature and focus on the \n",
    "materials the product is constructed from.\n",
    "\n",
    "Use at most 50 words.\n",
    "\n",
    "Technical specifications: ```{fact_sheet_chair}```\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12672bb2-f367-4b4c-981f-e2572abc6202",
   "metadata": {},
   "source": [
    "## Issue 2. Text focuses on the wrong details\n",
    "### Ask it to focus on the aspects that are relevant to the intended audience."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e7542e-7364-4409-95a8-1fc74866b537",
   "metadata": {},
   "source": [
    "prompt = f\"\"\"\n",
    "Your task is to help a marketing team create a \n",
    "description for a retail website of a product based \n",
    "on a technical fact sheet.\n",
    "\n",
    "Write a product description based on the information \n",
    "provided in the technical specifications delimited by \n",
    "triple backticks.\n",
    "\n",
    "The description is intended for furniture retailers, \n",
    "so should be technical in nature and focus on the \n",
    "materials the product is constructed from.\n",
    "\n",
    "At the end of the description, include every 7-character \n",
    "Product ID in the technical specification.\n",
    "\n",
    "After the description, include a table that gives the \n",
    "product's dimensions. The table should have two columns.\n",
    "In the first column include the name of the dimension. \n",
    "In the second column include the measurements in inches only.\n",
    "\n",
    "Give the table the title 'Product Dimensions'.\n",
    "\n",
    "Format everything as HTML that can be used in a website. \n",
    "Place the description in a <div> element.\n",
    "\n",
    "Technical specifications: ```{fact_sheet_chair}```\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1b1484-1a62-4add-9caf-5541c91ce508",
   "metadata": {},
   "source": [
    "## Issue 3. Description needs a table of dimensions\n",
    "### Ask it to extract information and organize it in a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15891ab7-baac-4d81-9368-24e545279be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Your task is to help a marketing team create a \n",
    "description for a retail website of a product based \n",
    "on a technical fact sheet.\n",
    "\n",
    "Write a product description based on the information \n",
    "provided in the technical specifications delimited by \n",
    "triple backticks.\n",
    "\n",
    "The description is intended for furniture retailers, \n",
    "so should be technical in nature and focus on the \n",
    "materials the product is constructed from.\n",
    "\n",
    "At the end of the description, include every 7-character \n",
    "Product ID in the technical specification.\n",
    "\n",
    "After the description, include a table that gives the \n",
    "product's dimensions. The table should have two columns.\n",
    "In the first column include the name of the dimension. \n",
    "In the second column include the measurements in inches only.\n",
    "\n",
    "Give the table the title 'Product Dimensions'.\n",
    "\n",
    "Format everything as HTML that can be used in a website. \n",
    "Place the description in a <div> element.\n",
    "\n",
    "Technical specifications: ```{fact_sheet_chair}```\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c041604-0d38-4e65-8b9d-d35c2ebb9053",
   "metadata": {},
   "source": [
    "## Load Python libraries to view HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6f3cd0-de4f-45c2-a086-1de07ae52d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing  html python library\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a54319-67aa-475d-b3d3-7f41933592f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# displaying contents using python display html function\n",
    "display(HTML(response))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
